input {
    stdin {
    }
    jdbc {
      # mysql 数据库链接,shop为数据库名
      jdbc_connection_string => "jdbc:mysql://192.168.11.40:3306/tms_1.4.2"
      # 用户名和密码
      jdbc_user => "root"
      jdbc_password => "123456"
      # 驱动
      jdbc_driver_library => "/opt/logstash-6.3.0/my_logstash/mysql-connector-java-5.1.44-bin.jar"
      # 驱动类名
      jdbc_driver_class => "com.mysql.jdbc.Driver"
      #开启分页查询
	  jdbc_paging_enabled => "true"
      jdbc_page_size => "50000"
	  #处理中文乱码问题
      codec => plain { charset => "UTF-8"}
	   #使用其它字段追踪，而不是用时间
      use_column_value => true
	  tracking_column => id
      record_last_run => true
	  #上一个sql_last_value值的存放文件路径, 必须要在文件中指定字段的初始值
      last_run_metadata_path => "/opt/logstash-6.3.0/my_logstash/station_parameter.txt"
	  clean_run => false
      # 执行的sql 文件路径+名称
      statement_filepath => "/opt/logstash-6.3.0/my_logstash/tms_site.sql"
      # 设置监听间隔  各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新
      schedule => "* * * * *"
      # 索引类型
      type => "tms_site_type"
    }
}

filter {
  json {
    source => "message"
  }
#  mutate {
#   add_field => [ "[lonlat]", "%{lng}" ]
#   add_field => [ "[lonlat]", "%{lat}" ]
# }
 
}

output {
  elasticsearch {
#ESIP地址与端口
  hosts => ["192.168.11.237:9200"]
#  protocol => "http"
#ES索引名称（自己定义的）
  index => "tms_site_index"
#覆盖以前的模板
#  template_overwrite => true
# 这是创建mapping 结构模板,测试无法通过
#template => "/opt/logstash-6.3.0/my_logstash/map_template.json"

#自增ID编号
  document_id => "%{id}"
#  cluster => "elasticsearch"
  }
  stdout {
#以JSON格式输出
  codec => json_lines
  }

}
